{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b037be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344019e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " NumPy ‚Üî PyTorch Comprehensive Practice\n",
      "================================================================================\n",
      "NumPy version: 2.1.2\n",
      "PyTorch version: 2.8.0+cu126\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\" NumPy ‚Üî PyTorch Comprehensive Practice\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0386de",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# Section 1: Basic Conversions\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb6ee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Section 1: Basic Conversions\n",
      "--------------------------------------------------\n",
      "1.1 NumPy ‚Üí PyTorch:\n",
      "    NumPy array:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "    PyTorch tensor:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "    Tensor dtype: torch.float32\n",
      "\n",
      "1.2 PyTorch ‚Üí NumPy:\n",
      "    PyTorch tensor:\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "    NumPy array:\n",
      "[[ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "    Array dtype: float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìå Section 1: Basic Conversions\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# NumPy to PyTorch\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n",
    "tensor_from_numpy = torch.from_numpy(np_array)\n",
    "\n",
    "print(\"1.1 NumPy ‚Üí PyTorch:\")\n",
    "print(f\"    NumPy array:\\n{np_array}\")\n",
    "print(f\"    PyTorch tensor:\\n{tensor_from_numpy}\")\n",
    "print(f\"    Tensor dtype: {tensor_from_numpy.dtype}\\n\")\n",
    "\n",
    "# PyTorch to NumPy\n",
    "pytorch_tensor = torch.tensor([[7, 8, 9], [10, 11, 12]], dtype=torch.float32)\n",
    "numpy_from_tensor = pytorch_tensor.numpy()\n",
    "\n",
    "print(\"1.2 PyTorch ‚Üí NumPy:\")\n",
    "print(f\"    PyTorch tensor:\\n{pytorch_tensor}\")\n",
    "print(f\"    NumPy array:\\n{numpy_from_tensor}\")\n",
    "print(f\"    Array dtype: {numpy_from_tensor.dtype}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a488f6ce",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# Section 2: Property Comparison\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706b7e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1 NumPy Array Properties:\n",
      "    Shape: (3, 4)\n",
      "    Dimensions: 2\n",
      "    Total elements: 12\n",
      "    Data type: float32\n",
      "    Memory usage: 48 bytes\n",
      "    Item size: 4 bytes\n",
      "    Strides: (16, 4)\n",
      "    C-contiguous: True\n",
      "    Fortran-contiguous: False\n",
      "\n",
      "2.2 PyTorch Tensor Properties:\n",
      "    Shape: torch.Size([3, 4])\n",
      "    Size: torch.Size([3, 4])\n",
      "    Dimensions: 2\n",
      "    Total elements: 12\n",
      "    Data type: torch.float32\n",
      "    Device: cpu\n",
      "    Layout: torch.strided\n",
      "    Strides: (4, 1)\n",
      "    Requires grad: False\n",
      "    Is contiguous: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a random array for comparison\n",
    "np_random = np.random.rand(3, 4).astype(np.float32)\n",
    "torch_random = torch.from_numpy(np_random)\n",
    "\n",
    "print(\"2.1 NumPy Array Properties:\")\n",
    "print(f\"    Shape: {np_random.shape}\")\n",
    "print(f\"    Dimensions: {np_random.ndim}\")\n",
    "print(f\"    Total elements: {np_random.size}\")\n",
    "print(f\"    Data type: {np_random.dtype}\")\n",
    "print(f\"    Memory usage: {np_random.nbytes} bytes\")\n",
    "print(f\"    Item size: {np_random.itemsize} bytes\")\n",
    "print(f\"    Strides: {np_random.strides}\")\n",
    "print(f\"    C-contiguous: {np_random.flags.c_contiguous}\")\n",
    "print(f\"    Fortran-contiguous: {np_random.flags.f_contiguous}\\n\")\n",
    "\n",
    "print(\"2.2 PyTorch Tensor Properties:\")\n",
    "print(f\"    Shape: {torch_random.shape}\")\n",
    "print(f\"    Size: {torch_random.size()}\")\n",
    "print(f\"    Dimensions: {torch_random.ndim}\")\n",
    "print(f\"    Total elements: {torch_random.numel()}\")\n",
    "print(f\"    Data type: {torch_random.dtype}\")\n",
    "print(f\"    Device: {torch_random.device}\")\n",
    "print(f\"    Layout: {torch_random.layout}\")\n",
    "print(f\"    Strides: {torch_random.stride()}\")\n",
    "print(f\"    Requires grad: {torch_random.requires_grad}\")\n",
    "print(f\"    Is contiguous: {torch_random.is_contiguous()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf672b2",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# Section 3: Memory Sharing vs Copying\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbf86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìå Section 3: Memory Sharing vs Copying\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Shared memory (view)\n",
    "print(\"3.1 Shared Memory (from_numpy creates a view):\")\n",
    "original_np = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "tensor_shared = torch.from_numpy(original_np)\n",
    "print(f\"    Original NumPy: {original_np}\")\n",
    "print(f\"    Tensor (shared): {tensor_shared}\")\n",
    "\n",
    "original_np[0] = 999.0\n",
    "print(f\"    After modifying NumPy[0] = 999:\")\n",
    "print(f\"    NumPy: {original_np}\")\n",
    "print(f\"    Tensor: {tensor_shared} ‚Üê Changed!\\n\")\n",
    "\n",
    "# Independent copy\n",
    "print(\"3.2 Independent Copy (tensor() creates a copy):\")\n",
    "original_np2 = np.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)\n",
    "tensor_copy = torch.tensor(original_np2)\n",
    "print(f\"    Original NumPy: {original_np2}\")\n",
    "print(f\"    Tensor (copy): {tensor_copy}\")\n",
    "\n",
    "original_np2[0] = 888.0\n",
    "print(f\"    After modifying NumPy[0] = 888:\")\n",
    "print(f\"    NumPy: {original_np2}\")\n",
    "print(f\"    Tensor: {tensor_copy} ‚Üê Unchanged!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e048cad",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# Section 4: Transpose and Contiguous Memory\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd155f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Section 4: Transpose and Contiguous Memory\n",
      "--------------------------------------------------\n",
      "4.1 NumPy Transpose:\n",
      "    Original shape: (2, 3)\n",
      "    Original:\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "    Original C-contiguous: True\n",
      "    Original strides: (12, 4)\n",
      "\n",
      "    Transposed shape: (3, 2)\n",
      "    Transposed:\n",
      "[[1. 4.]\n",
      " [2. 5.]\n",
      " [3. 6.]]\n",
      "    Transposed C-contiguous: False\n",
      "    Transposed strides: (4, 12)\n",
      "\n",
      "4.2 PyTorch Transpose:\n",
      "    Original shape: torch.Size([2, 3])\n",
      "    Original:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "    Original contiguous: True\n",
      "    Original strides: (3, 1)\n",
      "\n",
      "    Transposed shape: torch.Size([3, 2])\n",
      "    Transposed:\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "    Transposed contiguous: False ‚Üê Not contiguous!\n",
      "    Transposed strides: (1, 3)\n",
      "\n",
      "4.3 Making Tensor Contiguous:\n",
      "    After .contiguous(): True\n",
      "    New strides: (2, 1)\n",
      "\n",
      "4.4 NumPy Transposed ‚Üí PyTorch:\n",
      "    NumPy transposed C-contiguous: False\n",
      "    Resulting tensor contiguous: False\n",
      "    Tensor strides: (1, 3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìå Section 4: Transpose and Contiguous Memory\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# NumPy transpose\n",
    "print(\"4.1 NumPy Transpose:\")\n",
    "np_matrix = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.float32)\n",
    "np_transposed = np_matrix.T\n",
    "\n",
    "print(f\"    Original shape: {np_matrix.shape}\")\n",
    "print(f\"    Original:\\n{np_matrix}\")\n",
    "print(f\"    Original C-contiguous: {np_matrix.flags.c_contiguous}\")\n",
    "print(f\"    Original strides: {np_matrix.strides}\\n\")\n",
    "\n",
    "print(f\"    Transposed shape: {np_transposed.shape}\")\n",
    "print(f\"    Transposed:\\n{np_transposed}\")\n",
    "print(f\"    Transposed C-contiguous: {np_transposed.flags.c_contiguous}\")\n",
    "print(f\"    Transposed strides: {np_transposed.strides}\\n\")\n",
    "\n",
    "\n",
    "# PyTorch transpose\n",
    "print(\"4.2 PyTorch Transpose:\")\n",
    "torch_matrix = torch.from_numpy(np_matrix)\n",
    "torch_transposed = torch_matrix.t()\n",
    "\n",
    "print(f\"    Original shape: {torch_matrix.shape}\")\n",
    "print(f\"    Original:\\n{torch_matrix}\")\n",
    "print(f\"    Original contiguous: {torch_matrix.is_contiguous()}\")\n",
    "print(f\"    Original strides: {torch_matrix.stride()}\\n\")\n",
    "\n",
    "print(f\"    Transposed shape: {torch_transposed.shape}\")\n",
    "print(f\"    Transposed:\\n{torch_transposed}\")\n",
    "print(f\"    Transposed contiguous: {torch_transposed.is_contiguous()} ‚Üê Not contiguous!\")\n",
    "print(f\"    Transposed strides: {torch_transposed.stride()}\\n\")\n",
    "\n",
    "# Making it contiguous again\n",
    "print(\"4.3 Making Tensor Contiguous:\")\n",
    "torch_contiguous = torch_transposed.contiguous()\n",
    "print(f\"    After .contiguous(): {torch_contiguous.is_contiguous()}\")\n",
    "print(f\"    New strides: {torch_contiguous.stride()}\\n\")\n",
    "\n",
    "# NumPy transpose to PyTorch\n",
    "print(\"4.4 NumPy Transposed ‚Üí PyTorch:\")\n",
    "np_trans_to_torch = torch.from_numpy(np_transposed)\n",
    "print(f\"    NumPy transposed C-contiguous: {np_transposed.flags.c_contiguous}\")\n",
    "print(f\"    Resulting tensor contiguous: {np_trans_to_torch.is_contiguous()}\")\n",
    "print(f\"    Tensor strides: {np_trans_to_torch.stride()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a45947",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# Section 5: Practical Applications\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725bb788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Section 5: Practical Applications\n",
      "--------------------------------------------------\n",
      "5.1 NumPy Functions on PyTorch Tensors:\n",
      "    Original tensor: tensor([ 1.,  4.,  9., 16.])\n",
      "    After np.sqrt: tensor([1., 2., 3., 4.])\n",
      "\n",
      "5.2 Operation Chain (PyTorch ‚Üí NumPy ‚Üí PyTorch):\n",
      "    Random tensor:\n",
      "tensor([[ 0.8057, -0.6177, -0.2382],\n",
      "        [-2.9586, -1.4592, -1.5954]])\n",
      "    After softmax (via NumPy):\n",
      "tensor([[0.5523, 0.1330, 0.1945],\n",
      "        [0.0128, 0.0573, 0.0500]])\n",
      "    Sum (should be ~1.0): 1.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üìå Section 5: Practical Applications\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Using NumPy functions with PyTorch tensors\n",
    "print(\"5.1 NumPy Functions on PyTorch Tensors:\")\n",
    "tensor = torch.tensor([1.0, 4.0, 9.0, 16.0])\n",
    "print(f\"    Original tensor: {tensor}\")\n",
    "\n",
    "# Convert to NumPy, apply function, convert back\n",
    "np_temp = tensor.numpy()\n",
    "np_result = np.sqrt(np_temp)\n",
    "result_tensor = torch.from_numpy(np_result)\n",
    "print(f\"    After np.sqrt: {result_tensor}\\n\")\n",
    "\n",
    "# Complex operation chain\n",
    "print(\"5.2 Operation Chain (PyTorch ‚Üí NumPy ‚Üí PyTorch):\")\n",
    "torch_data = torch.randn(2, 3)\n",
    "print(f\"    Random tensor:\\n{torch_data}\")\n",
    "\n",
    "# Chain of operations\n",
    "np_data = torch_data.numpy()\n",
    "np_processed = np.exp(np_data) / np.sum(np.exp(np_data))  # Softmax\n",
    "torch_result = torch.from_numpy(np_processed)\n",
    "print(f\"    After softmax (via NumPy):\\n{torch_result}\")\n",
    "print(f\"    Sum (should be ~1.0): {torch_result.sum():.6f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dba359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Section 6: Memory Layout Visualization\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b252c13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Section 6: Memory Layout Visualization\n",
      "--------------------------------------------------\n",
      "6.1 3D Array/Tensor Memory Layout:\n",
      "NumPy 3D:\n",
      "    Shape: (2, 3, 4)\n",
      "    Strides: (48, 16, 4)\n",
      "    C-contiguous: True\n",
      "    F-contiguous: False\n",
      "PyTorch 3D:\n",
      "    Shape: torch.Size([2, 3, 4])\n",
      "    Strides: (12, 4, 1)\n",
      "    Contiguous: True\n",
      "\n",
      "6.2 After Permutation (2, 0, 1):\n",
      "NumPy permuted:\n",
      "    Shape: (4, 2, 3)\n",
      "    Strides: (4, 48, 16)\n",
      "    C-contiguous: False\n",
      "    F-contiguous: False\n",
      "PyTorch permuted:\n",
      "    Shape: torch.Size([4, 2, 3])\n",
      "    Strides: (1, 12, 4)\n",
      "    Contiguous: False\n",
      "\n",
      "6.3 After making PyTorch tensor contiguous:\n",
      "PyTorch contiguous:\n",
      "    Shape: torch.Size([4, 2, 3])\n",
      "    Strides: (6, 3, 1)\n",
      "    Contiguous: True\n",
      "\n",
      "================================================================================\n",
      " Practice Complete!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üìå Section 6: Memory Layout Visualization\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def print_memory_info(name, arr_or_tensor):\n",
    "    \"\"\"Helper function to print memory layout information\"\"\"\n",
    "    if isinstance(arr_or_tensor, np.ndarray):\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"    Shape: {arr_or_tensor.shape}\")\n",
    "        print(f\"    Strides: {arr_or_tensor.strides}\")\n",
    "        print(f\"    C-contiguous: {arr_or_tensor.flags.c_contiguous}\")\n",
    "        print(f\"    F-contiguous: {arr_or_tensor.flags.f_contiguous}\")\n",
    "    else:  # PyTorch tensor\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"    Shape: {arr_or_tensor.shape}\")\n",
    "        print(f\"    Strides: {arr_or_tensor.stride()}\")\n",
    "        print(f\"    Contiguous: {arr_or_tensor.is_contiguous()}\")\n",
    "\n",
    "# Create a 3D example to better show memory layout\n",
    "print(\"6.1 3D Array/Tensor Memory Layout:\")\n",
    "np_3d = np.arange(24).reshape(2, 3, 4).astype(np.float32)\n",
    "torch_3d = torch.from_numpy(np_3d)\n",
    "\n",
    "print_memory_info(\"NumPy 3D\", np_3d)\n",
    "print_memory_info(\"PyTorch 3D\", torch_3d)\n",
    "print()\n",
    "\n",
    "# Permute dimensions\n",
    "np_permuted = np_3d.transpose(2, 0, 1)\n",
    "torch_permuted = torch_3d.permute(2, 0, 1)\n",
    "\n",
    "print(\"6.2 After Permutation (2, 0, 1):\")\n",
    "print_memory_info(\"NumPy permuted\", np_permuted)\n",
    "print_memory_info(\"PyTorch permuted\", torch_permuted)\n",
    "print()\n",
    "\n",
    "# Show the effect of contiguous\n",
    "torch_cont = torch_permuted.contiguous()\n",
    "print(\"6.3 After making PyTorch tensor contiguous:\")\n",
    "print_memory_info(\"PyTorch contiguous\", torch_cont)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\" Practice Complete!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
